---
title: "Three Node Example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{three_node_example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## What is this for?

This shows inference for the DAG using data drawn from a fully connected three 
node DAG. The total number of possible three node DAGs is 25, which allows for a 
direct comparison between the estimated and actual frequency of samples for each 
DAG.

```{r setup}
library(dagmc)
library(magrittr)
```

Create conditional probability tables and plot the true DAG.

```{r, error = TRUE, fig.dim = c(5.0, 5.0)}
# Three Node confounder problem
levels <- c('yes', 'no')
all_levels <- list(A = levels, B = levels, C = levels)

# Two-edge model
bn_arr <- list()
bn_arr[[1]] <- gRbase::parray(c('A', 'B'), levels = all_levels,
                              values = c(0.67, 0.33, 0.33, 0.67))
bn_arr[[2]] <- gRbase::parray('B', levels = all_levels,
                              values = c(0.5, 0.5))
bn_arr[[3]] <- gRbase::parray(c('C', 'B'), levels = all_levels,
                              values = c(0.33, 0.67, 0.9, 0.1))

nodes <- names(all_levels)
cpt <- gRain::compileCPT(bn_arr)
gr_dag <- gRain::grain(cpt)
true_dag <- toBNLearn(gr_dag$dag)
plot(true_dag)
```

Draw samples from the true DAG. There appears to be a bug somewhere here such that
set.seed does not work when running simulate using gRain. So you will get
irreproducible results for this script.

```{r, error = TRUE}
data <- stats::simulate(gr_dag, nsim = 100, seed = 1)
knitr::kable(head(data))
```

Calculate correlation matrix of the data.
```{r, error = TRUE}
knitr::kable(cor(1*(data == 'yes')))
```

## Calculate analytical probabilities for each graph

Get all possible graphs. 

```{r, error = TRUE}
GetAllDAGs <- function(nodes) {

  n <- length(nodes)
  n_tri <- n*(n - 1)/2
  tri_comb <- rep(list(c(0L, 1L)), n_tri)
  tri_val <- expand.grid(tri_comb)
  
  node_perm <- gtools::permutations(length(nodes), length(nodes), nodes)
  all_dags <- list()
  n <- 1
  for (i in 1:nrow(node_perm)) {
    for (j in 1:nrow(tri_val)) {
      mat <- matrix(
        0L,
        nrow = length(nodes), 
        ncol = length(nodes),
        dimnames = list(node_perm[i, ], node_perm[i, ])
        )
      mat[upper.tri(mat)] <- as.integer(tri_val[j, ])
      mat <- mat[nodes, nodes]
      
      all_dags[[n]] <- mat
      n <- n + 1
    }
  }
  all_dags <- unique(all_dags)
  
  return(all_dags)
}

all_dags <- GetAllDAGs(nodes)
```

Score all possible DAGs against the simulated data.

```{r, error = TRUE}
scorer <- CreateScorer(data = data, type = 'bde', cache = TRUE)

score_all_dags <- all_dags |>
  lapply(ScoreDAG, scorer = scorer) |>
  unlist()
hash_all_dags <- all_dags |>
  lapply(rlang::hash) |> 
  unlist()
```

Convert the scores into expected probabilities.

```{r, error = TRUE}
log_z <- LogSumExp(score_all_dags)
log_p <- score_all_dags - log_z
p_true <- exp(log_p)

p_summary <- data.frame(
  hash_dag = hash_all_dags, 
  p_true = p_true
)
```

## Sample from the posterior using MCMC

This gets n_results samples for each core. 

```{r, error = TRUE}
set.seed(1)
n_results <- 1e4
n_chains <- 2

init_partitions <- list()
for (i in 1:n_chains) {
  init_dag <- UniformlySampleDAG(names(data))
  init_partitions[[i]] <- GetPartitionedNodesFromAdjacencyMatrix(init_dag)
}

# Only use the move-node proposal. There are some minor issues with following 
# detailed balance by using the others.
system.time(
  chains <- SampleChains(n_results,
                         init_partitions,
                         transition = PartitionMCMC(
                           proposal = DefaultProposal(p = c(0.0, 1.0, 0.0, 0.0, 0.0))
                           ),
                         scorer = scorer,
                         n_parallel_chains = n_chains)
)
```

## Check the chains for convergence 

Looking at the trace of the partition log score.

```{r, error = TRUE, fig.dim = c(6.0, 4.0)}
PlotScoreTrace(chains, ylab = 'log(partition score)', type = 'l')
```

Converting the partitions into DAGs.

```{r, error = TRUE}
n_burnin <- 500
eq_chains <- chains[(1 + n_burnin):n_results]
eq_dag_chains <- PartitiontoDAG(eq_chains, scorer)
```

Plot trace of DAG scores for equilibrium states.

```{r, error = TRUE, fig.dim = c(6.0, 4.0)}
PlotScoreTrace(eq_chains, attribute = 'log_score', ylab = 'log(DAG score)', type = 'l')
```

## Convergence of the score trace

On inspection the score trace for both partitions and DAGs appears to have 
converged across chains. TODO: I should show a rolling average for each pairwise edge.

## Analysing acceptance rates

Acceptance per proposal after burnin.

```{r, error = TRUE}
prop_accept <- CalculateAcceptanceRates(eq_chains, group_by = 'proposal_used')
knitr::kable(prop_accept)
```

Overall acceptance proposal.

```{r, error = TRUE}
total_accept <- CalculateAcceptanceRates(eq_chains, group_by = 'chain')
knitr::kable(total_accept)
```


## Estimating probabilities for each DAG

This shows the estimate (p_true) and true (p_true) probabilities for each
DAG that was visited in the sampling procedure.

```{r, error = TRUE, fig.dim = c(5.0, 5.0)}
collect_dags <- eq_dag_chains |>
  FlattenChains() |>
  CollectUniqueObjects()
p_ordered_dags <- sort(collect_dags$log_sampling_prob,
                       decreasing = TRUE,
                       index.return = TRUE)

for (i in 1:length(collect_dags$state)) {
  adj <- collect_dags$state[[p_ordered_dags$ix[i]]]
  bn_obj <- toBNLearn(adj)
  plot(bn_obj)
  
  p_est <- p_ordered_dags$x[i] |>
    exp() |>
    round(4)
  
  p_true <- p_summary |>
    dplyr::filter(hash_dag == rlang::hash(adj)) |>
    dplyr::select(p_true) |>
    as.numeric() |>
    round(4)
  
  t <- paste('p_est: ', round(p_est, 4),
             ', p_true: ', round(p_true, 4), sep = '')
  graphics::text(300, 0, t)
  
}
```
